"""
Hospital Agent -- Brain

LLM-driven conversation logic. The hospital agent acts as a phone system
that interacts with callers. Supports conversational and DTMF modes.
Everything is dynamically generated by the LLM based on the conversation.
"""

from __future__ import annotations
import json
import logging

from groq import Groq

from hospital_agent.config import settings

logger = logging.getLogger(__name__)

_client: Groq | None = None


def _get_client() -> Groq:
    global _client
    if _client is None:
        _client = Groq(api_key=settings.groq_api_key)
    return _client


HOSPITAL_SYSTEM_PROMPT = """You are Maria, a friendly and professional phone system AI agent \
at a hospital. You handle incoming calls and help callers with their requests.

You are currently operating in {mode} MODE.

--- CONVERSATIONAL MODE ---
- Greet the caller warmly and ask how you can help
- Listen to what they need
- Repeat back what you understood and ask "Is that correct?"
- Ask for their name and mobile number if they haven't provided them yet
- Repeat the personal details back and confirm
- Say "Please give me a minute" (set hold to true)
- Announce the result with all relevant details
- Say a warm goodbye

--- DTMF MODE ---
- Greet the caller and ask for their name and mobile number
- Repeat back and confirm identity
- Present a MAIN MENU of numbered options relevant to the type of service
  Format: "If you need X press 1, If you need Y press 2, ..."
  Include options like: previous appointment, new appointment, cancel,
  reschedule, check status, talk to agent, repeat, end call
- After each selection, confirm what they chose
- Present relevant SUB-MENUS (department/specialty, specific doctor, etc.)
  each with numbered options -- include realistic choices for the domain
- For date/time: offer "today press 1, tomorrow press 2, manually enter date press 3"
  If they choose manual: ask them to enter the date in ddmmyyyy format
- Confirm the full details
- Say "Please give me a minute" (set hold to true)
- Announce the result with all details
- Say a warm goodbye

--- RULES ---
1. Generate ONLY what you (Maria) say. Do not generate the caller's lines.
2. Be natural, warm, and professional. Use the hospital name in greetings.
3. Always confirm details before proceeding to the next step.
4. In DTMF mode, always list options clearly with "press N" format.
5. Adapt menus to be relevant to the caller's request domain.
6. The final success message must include ALL confirmed details.
7. Never break character. You are Maria at the hospital.
8. Generate realistic, plausible options in menus.

--- CALLER CONTEXT ---
The caller is calling about: {intent_summary}

Return ONLY this JSON for each turn:
{{
  "speech": "exactly what you say to the caller",
  "expects": "speech" | "dtmf" | "none",
  "hold": false,
  "call_should_end": false
}}

"expects":
  - "speech" = you asked the caller a question or want a verbal response
  - "dtmf" = you presented a menu and want them to press a key
  - "none" = no response needed (farewell, hold message)
"hold": true = you need to process something (triggers a brief pause before your next turn)
"call_should_end": true ONLY for the absolute final goodbye message"""


async def generate_turn(
    mode: str,
    intent_summary: str,
    conversation_history: list[dict],
) -> dict:
    """
    Generate the hospital agent's next turn.

    Args:
        mode: "conversational" or "dtmf"
        intent_summary: JSON string of the caller's intent
        conversation_history: list of {role, text} dicts

    Returns:
        dict with speech, expects, hold, call_should_end
    """
    client = _get_client()

    system = HOSPITAL_SYSTEM_PROMPT.format(
        mode=mode.upper(),
        intent_summary=intent_summary,
    )

    messages = [{"role": "system", "content": system}]

    # Build conversation as alternating assistant (hospital) / user (caller) messages
    for turn in conversation_history:
        if turn["role"] == "hospital":
            messages.append({"role": "assistant", "content": turn["text"]})
        else:
            messages.append({"role": "user", "content": turn["text"]})

    # If no conversation yet or last message was from caller, hospital speaks next
    if not conversation_history or conversation_history[-1]["role"] == "caller":
        messages.append({
            "role": "user",
            "content": "(Generate your next response as the hospital agent.)",
        })

    try:
        response = client.chat.completions.create(
            model=settings.groq_llm_model,
            messages=messages,
            temperature=0.3,
            max_tokens=1024,
            response_format={"type": "json_object"},
        )
        raw = response.choices[0].message.content.strip()
        result = json.loads(raw)

        # Validate required fields
        result.setdefault("speech", "")
        result.setdefault("expects", "speech")
        result.setdefault("hold", False)
        result.setdefault("call_should_end", False)

        logger.info(f"[Brain] Generated: {result['speech'][:80]}...")
        return result
    except json.JSONDecodeError:
        logger.error(f"[Brain] JSON parse failed: {raw[:200]}")
        return {
            "speech": "I apologize, could you please repeat that?",
            "expects": "speech",
            "hold": False,
            "call_should_end": False,
        }
    except Exception as e:
        logger.error(f"[Brain] LLM call failed: {e}")
        raise
