"""
Agent 3 -- Action Agent

Responsibilities:
  1. Receive messages from the other party (classified or raw)
  2. Use LLM to decide the appropriate action (speak, DTMF, wait, end call)
  3. Generate natural, dynamic speech responses
  4. All dialogue is LLM-generated -- nothing is hardcoded
"""

from __future__ import annotations
import json
import logging
from typing import Callable, Optional

from groq import Groq

from backend.models.schemas import (
    IVRClassification, IVRPromptType, UserIntent,
    AgentAction, ActionType, CallState,
)
from backend.config import settings

logger = logging.getLogger(__name__)

_client: Groq | None = None


def _get_client() -> Groq:
    global _client
    if _client is None:
        _client = Groq(api_key=settings.groq_api_key)
    return _client


AGENT_SYSTEM_PROMPT = """\
You are an AI phone agent making a call to {target_entity} on behalf of a user.

--- USER'S REQUEST ---
{intent_summary}

--- USER DETAILS ---
Name: {user_name}
Phone: {user_phone}

--- HOW TO RESPOND ---

### RULE 0 -- SHORT ACKNOWLEDGMENTS (highest priority, check first)
If the other party says a very short phrase that is just echoing or confirming what \
you said -- such as "One.", "Two.", "Thank you.", "Okay.", "Got it.", "Please hold.", \
"Please wait." -- return "wait". The IVR is still processing; do NOT speak.

The signal: if the message is fewer than ~8 words AND contains no question, menu \
options, or instruction directed at you, return "wait".

### RULE 1 -- NUMBERED MENU
If the other party reads out a list of options ("Say 1 for X, say 2 for Y, ..."):
- Read EVERY option in the list carefully.
- Pick the number whose description best matches the user's request.
- Say ONLY that number as a single word. Nothing else.
- Example: if "Say 7 for dermatologist" matches the request, respond with just "7".

### RULE 2 -- OPEN GREETING ("How can I help you?", "What can I do for you?")
State the full request in ONE clear sentence. Include all relevant details. \
Do NOT provide name or phone unless they were asked for.
Example: "Hello, I would like to book an appointment with a dermatologist at \
Apollo Hospital Madinaguda on 15th April 2026 at 1 PM."

### RULE 3 -- ASKED FOR NAME
Provide only the name. Example: "My name is Bala."

### RULE 4 -- ASKED FOR PHONE / MOBILE NUMBER
Read out the digits one by one. Example: "9 4 9 1 0 2 5 6 6 7."

### RULE 5 -- ASKED FOR DATE
Say the date naturally. Example: "15th April 2026."

### RULE 6 -- ASKED FOR TIME
Say the time naturally. Example: "1 PM."

### RULE 7 -- CONFIRMATION ("Is that correct?", "Shall I proceed?")
Confirm briefly: "Yes, that is correct." or "Yes, please go ahead."

### RULE 8 -- HOLD / MUSIC / "Please wait while we process"
Return "wait" silently.

### RULE 9 -- SUCCESS / BOOKING CONFIRMED
Say a brief thanks and use action_type "end_call".

### RULE 10 -- FAREWELL
Say goodbye and use action_type "end_call".

### RULE 11 -- ANYTHING ELSE
Respond naturally and concisely to move the task forward. \
Do NOT volunteer information (name, phone, date) unless explicitly asked for it.

--- RESPONSE FORMAT ---
Return ONLY valid JSON:
{{
  "action_type": "speak" | "wait" | "end_call",
  "speech_text": "what to say out loud (null when action_type is wait)",
  "dtmf_digits": null,
  "reasoning": "which rule was applied and why"
}}

Constraints:
- For menu selections, speech_text must be a single number only -- no extra words.
- Never volunteer name, phone, or date before being asked.
- Never repeat yourself -- vary phrasing naturally across turns.
- Use "wait" whenever the other party is just echoing, processing, or playing hold music.\
"""


class ActionAgent:
    """
    Decides actions in response to the other party's messages.
    All responses are dynamically generated by the LLM.
    """

    def __init__(
        self,
        call_state: CallState,
        on_action: Callable[[AgentAction], None] | None = None,
    ):
        self.call_state = call_state
        self.on_action = on_action
        self._conversation_history: list[dict] = []

    async def handle_classification(
        self,
        classification: IVRClassification,
    ) -> AgentAction:
        """
        Receive a classified prompt and decide what to do.
        """
        logger.info(
            f"[Agent3] Handling {classification.prompt_type}: "
            f"{classification.raw_transcript[:80]}..."
        )

        self._conversation_history.append({
            "role": "other_party",
            "text": classification.raw_transcript,
        })

        action = await self._generate_action(
            classification.raw_transcript,
            classification,
        )

        self._log_action(action)

        if action.speech_text:
            self._conversation_history.append({
                "role": "agent",
                "text": action.speech_text,
            })

        if self.on_action:
            self.on_action(action)

        return action

    async def handle_raw_transcript(self, transcript: str) -> AgentAction:
        """
        Handle a raw transcript (from real call STT) without prior classification.
        Classifies internally then generates an action.
        """
        from backend.services import groq_llm

        logger.info(f"[Agent3] Raw transcript: {transcript[:80]}...")

        self._conversation_history.append({
            "role": "other_party",
            "text": transcript,
        })

        action = await self._generate_action(transcript)

        self._log_action(action)

        if action.speech_text:
            self._conversation_history.append({
                "role": "agent",
                "text": action.speech_text,
            })

        if self.on_action:
            self.on_action(action)

        return action

    async def _generate_action(
        self,
        other_party_text: str,
        classification: IVRClassification | None = None,
    ) -> AgentAction:
        """Use LLM to decide the action and generate natural speech."""
        intent = self.call_state.user_intent
        client = _get_client()

        target = intent.target_entity or "the other party"

        system = AGENT_SYSTEM_PROMPT.format(
            target_entity=target,
            intent_summary=self._build_intent_summary(intent),
            user_name=intent.user_name or "Unknown",
            user_phone=intent.user_phone or "Unknown",
        )

        messages = [{"role": "system", "content": system}]

        for turn in self._conversation_history:
            if turn["role"] == "other_party":
                messages.append({"role": "user", "content": turn["text"]})
            else:
                messages.append({"role": "assistant", "content": turn["text"]})

        if (
            not self._conversation_history
            or self._conversation_history[-1]["role"] != "other_party"
        ):
            messages.append({"role": "user", "content": other_party_text})

        try:
            response = client.chat.completions.create(
                model=settings.groq_llm_model,
                messages=messages,
                temperature=0.3,
                max_tokens=512,
                response_format={"type": "json_object"},
            )
            raw = response.choices[0].message.content.strip()
            result = json.loads(raw)

            action_type = {
                "speak": ActionType.SPEAK,
                "dtmf": ActionType.DTMF,
                "wait": ActionType.WAIT,
                "end_call": ActionType.END_CALL,
            }.get(result.get("action_type", "speak"), ActionType.SPEAK)

            return AgentAction(
                action_type=action_type,
                speech_text=result.get("speech_text"),
                dtmf_digits=result.get("dtmf_digits"),
                reasoning=result.get("reasoning", "LLM-generated response"),
            )

        except json.JSONDecodeError:
            logger.error(f"[Agent3] JSON parse failed: {raw[:200]}")
            return AgentAction(
                action_type=ActionType.SPEAK,
                speech_text="Could you please repeat that?",
                reasoning="JSON parse error, asking to repeat",
            )
        except Exception as e:
            logger.error(f"[Agent3] LLM call failed: {e}")
            return AgentAction(
                action_type=ActionType.SPEAK,
                speech_text="I am sorry, could you repeat that?",
                reasoning=f"LLM error: {str(e)}",
            )

    def _build_intent_summary(self, intent: UserIntent) -> str:
        """Build a human-readable summary of the user's intent."""
        parts = []

        # Use task_description if available, otherwise map from intent type
        if intent.task_description:
            parts.append(intent.task_description.capitalize())
        else:
            action_map = {
                "book_appointment": "Book a new appointment",
                "cancel_appointment": "Cancel an existing appointment",
                "reschedule_appointment": "Reschedule an appointment",
                "check_status": "Check appointment status",
                "general_inquiry": "Make a general inquiry",
                "complaint": "File a complaint",
                "phone_call": "Make a phone call",
            }
            parts.append(action_map.get(intent.intent.value, intent.intent.value))

        if intent.target_entity:
            parts.append(f"Target: {intent.target_entity}")
        if intent.doctor_specialty:
            parts.append(f"Specialty: {intent.doctor_specialty}")
        if intent.doctor_name:
            parts.append(f"Doctor: {intent.doctor_name}")
        if intent.hospital_name:
            hospital = intent.hospital_name
            if intent.hospital_branch:
                hospital += f", {intent.hospital_branch}"
            if intent.hospital_city:
                hospital += f", {intent.hospital_city}"
            parts.append(f"Hospital: {hospital}")
        if intent.appointment_date:
            parts.append(f"Date: {intent.appointment_date}")

        return ". ".join(parts)

    def _log_action(self, action: AgentAction) -> None:
        match action.action_type:
            case ActionType.SPEAK:
                logger.info(f"[Agent3] Speaking: {action.speech_text}")
            case ActionType.DTMF:
                logger.info(f"[Agent3] Pressing DTMF: {action.dtmf_digits}")
            case ActionType.END_CALL:
                logger.info(f"[Agent3] Ending call: {action.speech_text}")
            case ActionType.WAIT:
                logger.info(f"[Agent3] Waiting: {action.reasoning}")
